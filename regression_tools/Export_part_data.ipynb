{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from urllib.parse import urlparse\n",
    "from urllib import parse\n",
    "from lib.build_regressions_features_no_na import MixedFeatureData\n",
    "from lib.explore_data import ExploratoryAnalysis\n",
    "from lib.regressions_statsmodel import MixedClassificationModel, RegressionModel\n",
    "\n",
    "%matplotlib inline\n",
    "FOLLOWER_URL = os.environ['FOLLOWER_URL']\n",
    "                          \n",
    "def make_connection():\n",
    "    url_output = FOLLOWER_URL\n",
    "    url = urlparse(url_output)\n",
    "    conn = psycopg2.connect(\n",
    "        database=url.path[1:],\n",
    "        user=url.username,\n",
    "        password=url.password,\n",
    "        host=url.hostname\n",
    "    )\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# START HERE\n",
    "## The cell below contains all the mission specific data. Here you will specifity the mission id, the independent variables, the dependent variable, and the definitions of positive and negative outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THESE VALUES\n",
    "mission_id = \"25614\"\n",
    "# ONLY USE SINGLE QUESTIONS FOR DEPENDENT AND INDEPENDENT VARIABLES IN FORMAT 'PART_NUM-QUESTION_NUM'\n",
    "# ALL \"4-4\", \"4-5\",\"4-6\", \"4-10\",\"4-11\",\"4-12\", \"4-13\",\"4-14\",\"4-15\",\"4-17\",\"4-18\",\"4-19\",\"4-21\"\n",
    "continuous_independent_variables = [\n",
    "    \"4-6\", \"4-10\",\"4-4\",\"4-5\",\"4-11\",\"4-17\"\n",
    "]\n",
    "# NOTE MULTIPLE QUESTIONS NEED TO BE CATEGORICAL\n",
    "categorical_independent_variables = []\n",
    "binary_independent_variables = []\n",
    "dependent_variable = \"4-2\"\n",
    "negative_outcomes = [\n",
    "\"Moderately satisfied\",\n",
    "\"Slightly satisfied\",\n",
    "\"Neither satisfied nor dissatisfied\",\n",
    "\"Slightly dissatisfied\",\n",
    "\"Moderately dissatisfied\",\n",
    "\"Extremely dissatisfied\"\n",
    "]\n",
    "positive_outcomes = [\"Extremely satisfied\"]\n",
    "demo_independent_variables = []\n",
    "tag_independent_variables = []\n",
    "#mutually exclusive scout groups only at this time\n",
    "scout_group_independent_variables = []\n",
    "#response_data = pd.read_pickle(\"mission_\" + mission_id + \"_data.pkl\")\n",
    "question_response_filtering = {}\n",
    "grouping = 'user_id'\n",
    "ethnicity_filters = []\n",
    "education_filters = []\n",
    "tag_filters = []\n",
    "scout_group_filters = [\"Pixel\",\"Apple\",\"Samsung\",\"Bose\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After entering the information above, go to Cell -> Run All to see your regression results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collected questions\n",
      "collected snippets\n",
      "collected scout groups\n",
      "collected responses\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function connection.close>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnc = make_connection()\n",
    "questions = pd.read_sql_query(\n",
    "    \"\"\"with m_questions as (select id as question_id, label, type, position as question_position,\n",
    "                            part_id, structure from questions where type in \n",
    "                            ('SingleQuestion', 'MultipleQuestion', 'NumberQuestion')\n",
    "                            and mission_id = \"\"\"\n",
    "    + mission_id\n",
    "    + \"\"\"),\n",
    "       m_parts as (select id as part_id, position as part_position from parts where\n",
    "                   mission_id = \"\"\"\n",
    "    + mission_id\n",
    "    + \"\"\")\n",
    "    select question_id, label, type, question_position, m_parts.part_id, part_position,\n",
    "    structure from m_questions join m_parts on m_questions.part_id = m_parts.part_id\"\"\",\n",
    "    cnc,\n",
    ")\n",
    "print(\"collected questions\")\n",
    "\n",
    "question_list = (\n",
    "    \"(\" + \",\".join([str(a) for a in questions[\"question_id\"].tolist()]) + \")\"\n",
    ")\n",
    "snippets = pd.read_sql_query(\n",
    "    \"\"\"select id as snippet_id, user_id, assignment_id from snippets where mission_id = \"\"\"\n",
    "    + mission_id,\n",
    "    cnc,\n",
    ")\n",
    "print(\"collected snippets\")\n",
    "scout_group_names = (\n",
    "    \"(\"\n",
    "    + \",\".join([\"'\" + str(sg) + \"'\" for sg in scout_group_independent_variables])\n",
    "    + \")\"\n",
    ")\n",
    "assignments = pd.read_sql_query(\n",
    "    \"\"\"select id as assignment_id, user_id from assignments where \n",
    "          mission_id = \"\"\"\n",
    "    + mission_id\n",
    "    ,cnc)\n",
    "assignment_list = \"(\" + ','.join([str(aid) for aid in assignments['assignment_id'].unique()]) +\")\"\n",
    "assignment_groups = pd.read_sql_query(\n",
    "    \"\"\"select assignment_id, scout_group_id from assignments_scout_groups\n",
    "    where assignment_id in \"\"\" + assignment_list,\n",
    "    cnc\n",
    ")\n",
    "groups = pd.read_sql_query(\n",
    "    \"\"\"select id as scout_group_id, name as scout_group from scout_groups\n",
    "    \"\"\",\n",
    "    cnc)\n",
    "scout_groups = pd.merge(\n",
    "    assignment_groups,\n",
    "    groups[groups['scout_group'].isin(scout_group_filters)],\n",
    "    on='scout_group_id'\n",
    ")\n",
    "print(\"collected scout groups\")\n",
    "\n",
    "\n",
    "snippet_list = (\n",
    "    \"(\" + \",\".join([str(a) for a in snippets[\"snippet_id\"].tolist()]) + \")\"\n",
    ")\n",
    "responses = pd.read_sql_query(\n",
    "    \"\"\"select  id as response_id, snippet_id, question_id, \n",
    "    answers from responses where snippet_id in \"\"\"\n",
    "    + snippet_list,\n",
    "    cnc,\n",
    ")\n",
    "print(\"collected responses\")\n",
    "snippets_tags = pd.read_sql_query(\n",
    "    \"\"\"Select tag_id, snippet_id from snippets_tags where snippet_id in \"\"\"\n",
    "    + snippet_list,\n",
    "    cnc,\n",
    ")\n",
    "tag_list = \"(\" + \",\".join([str(a) for a in snippets_tags[\"tag_id\"].tolist()]) + \")\"\n",
    "tags = pd.read_sql_query(\n",
    "    \"\"\"select id as tag_id, name as tag from tags where id in \"\"\" + tag_list, cnc\n",
    ")\n",
    "\n",
    "snippets_tags = pd.merge(snippets_tags, tags, on=\"tag_id\")\n",
    "tagged_snippets = pd.merge(snippets, snippets_tags, on=\"snippet_id\", how=\"left\")\n",
    "user_list = \"(\" + \",\".join([str(a) for a in assignments[\"user_id\"].tolist()]) + \")\"\n",
    "users = pd.read_sql_query(\n",
    "    \"\"\"select id as user_id, ethnicity, education, household_income, birthday, gender from users where\n",
    "                                 id in \"\"\"\n",
    "    + user_list,\n",
    "    cnc,\n",
    ")\n",
    "user_snippets = pd.merge(tagged_snippets, users, on=\"user_id\", how=\"left\")\n",
    "user_snippets = pd.merge(user_snippets, scout_groups, on=\"assignment_id\", how=\"left\")\n",
    "response_data = pd.merge(responses, questions, on=\"question_id\")\n",
    "response_data = pd.merge(response_data, user_snippets, on=\"snippet_id\", how=\"left\")\n",
    "cnc.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#response_data.to_pickle('mission_'+mission_id+'_data.pkl')\n",
    "#response_data.to_csv('mission_'+mission_id+'_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_data['birthday'] = response_data['birthday'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = MixedFeatureData(\n",
    "    response_data,\n",
    "    dependent_variable,\n",
    "    continuous_independent_variables,\n",
    "    binary_independent_variables,\n",
    "    categorical_independent_variables,\n",
    "    positive_outcomes,\n",
    "    negative_outcomes,\n",
    "    demo_independent_variables,\n",
    "    tag_independent_variables,\n",
    "    scout_group_independent_variables,\n",
    "    grouping,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = [p for p in response_data['part_position'].unique()]\n",
    "#parts\n",
    "part_questions = [response_data[response_data['part_position'] == p]['question_position'].unique() for p in parts]\n",
    "part_questions\n",
    "question_names = [[str(1+p)+'-'+str(1+q) for q in part_questions[p]] for p in parts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = fd.processed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parts:\n",
    "    \n",
    "    part_df = (\n",
    "        processed[processed['question_name'].isin(question_names[p])]\n",
    "        [['snippet_id','question_name','response']]\n",
    "        .pivot(\n",
    "            index='snippet_id', columns=\"question_name\", values=\"response\"\n",
    "        )\n",
    "    )\n",
    "    part_df = pd.merge(\n",
    "        part_df,\n",
    "        user_snippets,\n",
    "        on='snippet_id'\n",
    "    )\n",
    "    part_df.to_csv('mission_'+mission_id+'_part_'+str(p)+'_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "for independent_variable in fd.independent_variables:\n",
    "    if independent_variable in fd.binary_independent_variables or\\\n",
    "       independent_variable in fd.dummies:\n",
    "        logistic_regression.simulate_binary_outcomes(independent_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
