{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from urllib.parse import urlparse\n",
    "from urllib import parse\n",
    "from lib.build_regressions_features_demo import MixedFeatureData\n",
    "from lib.explore_data import ExploratoryAnalysis\n",
    "from lib.regressions import MixedClassificationModel\n",
    "\n",
    "%matplotlib inline\n",
    "FOLLOWER_URL = os.environ['FOLLOWER_URL']\n",
    "                          \n",
    "def make_connection():\n",
    "    url_output = FOLLOWER_URL\n",
    "    url = urlparse(url_output)\n",
    "    conn = psycopg2.connect(\n",
    "        database=url.path[1:],\n",
    "        user=url.username,\n",
    "        password=url.password,\n",
    "        host=url.hostname\n",
    "    )\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# START HERE\n",
    "## The cell below contains all the mission specific data. Here you will specifity the mission id, the independent variables, the dependent variable, and the definitions of positive and negative outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CHANGE THESE VALUES\n",
    "mission_id = \"25614\"\n",
    "# ONLY USE SINGLE QUESTIONS FOR DEPENDENT AND INDEPENDENT VARIABLES IN FORMAT 'PART_NUM-QUESTION_NUM'\n",
    "# ALL \"4-4\", \"4-5\",\"4-6\", \"4-10\",\"4-11\",\"4-12\", \"4-13\",\"4-14\",\"4-15\",\"4-17\",\"4-18\",\"4-19\",\"4-21\"\n",
    "continuous_independent_variables = [\"4-4\", \"4-5\",\"4-6\", \"4-10\",\n",
    "                                    \"4-12\",\"4-15\",\n",
    "                                    \"4-17\",\"4-18\",\"4-19\",\"4-21\"]\n",
    "# NOTE MULTIPLE QUESTIONS NEED TO BE CATEGORICAL\n",
    "categorical_independent_variables = []\n",
    "binary_independent_variables = []\n",
    "dependent_variable = \"4-2\"\n",
    "negative_outcomes = [\n",
    "\"Moderately satisfied\",\n",
    "\"Slightly satisfied\",\n",
    "\"Neither satisfied nor dissatisfied\",\n",
    "\"Slightly dissatisfied\",\n",
    "\"Moderately dissatisfied\",\n",
    "\"Extremely dissatisfied\"\n",
    "]\n",
    "positive_outcomes = [\"Extremely satisfied\"]\n",
    "demo_independent_variables = ['age']\n",
    "tag_independent_variables = []\n",
    "#mutually exclusive scout groups only at this time\n",
    "scout_group_independent_variables = []\n",
    "#response_data = pd.read_pickle(\"mission_\" + mission_id + \"_data.pkl\")\n",
    "question_response_filtering = {}\n",
    "grouping = 'user_id'\n",
    "ethnicity_filters = []\n",
    "education_filters = []\n",
    "tag_filters = []\n",
    "scout_group_filters = [\"Apple\",\"Samsung\",\"Pixel\",\"Bose\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After entering the information above, go to Cell -> Run All to see your regression results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnc = make_connection()\n",
    "questions = pd.read_sql_query(\n",
    "    \"\"\"with m_questions as (select id as question_id, label, type, position as question_position,\n",
    "                            part_id, structure from questions where type in \n",
    "                            ('SingleQuestion', 'MultipleQuestion', 'NumberQuestion')\n",
    "                            and mission_id = \"\"\"\n",
    "    + mission_id\n",
    "    + \"\"\"),\n",
    "       m_parts as (select id as part_id, position as part_position from parts where\n",
    "                   mission_id = \"\"\"\n",
    "    + mission_id\n",
    "    + \"\"\")\n",
    "    select question_id, label, type, question_position, m_parts.part_id, part_position,\n",
    "    structure from m_questions join m_parts on m_questions.part_id = m_parts.part_id\"\"\",\n",
    "    cnc,\n",
    ")\n",
    "print(\"collected questions\")\n",
    "\n",
    "question_list = (\n",
    "    \"(\" + \",\".join([str(a) for a in questions[\"question_id\"].tolist()]) + \")\"\n",
    ")\n",
    "snippets = pd.read_sql_query(\n",
    "    \"\"\"select id as snippet_id, user_id, assignment_id from snippets where mission_id = \"\"\"\n",
    "    + mission_id,\n",
    "    cnc,\n",
    ")\n",
    "print(\"collected snippets\")\n",
    "scout_group_names = (\n",
    "    \"(\"\n",
    "    + \",\".join([\"'\" + str(sg) + \"'\" for sg in scout_group_independent_variables])\n",
    "    + \")\"\n",
    ")\n",
    "assignments = pd.read_sql_query(\n",
    "    \"\"\"select id as assignment_id, user_id from assignments where \n",
    "          mission_id = \"\"\"\n",
    "    + mission_id\n",
    "    ,cnc)\n",
    "assignment_list = \"(\" + ','.join([str(aid) for aid in assignments['assignment_id'].unique()]) +\")\"\n",
    "assignment_groups = pd.read_sql_query(\n",
    "    \"\"\"select assignment_id, scout_group_id from assignments_scout_groups\n",
    "    where assignment_id in \"\"\" + assignment_list,\n",
    "    cnc\n",
    ")\n",
    "groups = pd.read_sql_query(\n",
    "    \"\"\"select id as scout_group_id, name as scout_group from scout_groups\n",
    "    \"\"\",\n",
    "    cnc)\n",
    "scout_groups = pd.merge(\n",
    "    assignment_groups,\n",
    "    groups[groups['scout_group'].isin(scout_group_filters)],\n",
    "    on='scout_group_id'\n",
    ")\n",
    "print(\"collected scout groups\")\n",
    "\n",
    "\n",
    "snippet_list = (\n",
    "    \"(\" + \",\".join([str(a) for a in snippets[\"snippet_id\"].tolist()]) + \")\"\n",
    ")\n",
    "responses = pd.read_sql_query(\n",
    "    \"\"\"select  id as response_id, snippet_id, question_id, \n",
    "    answers from responses where snippet_id in \"\"\"\n",
    "    + snippet_list,\n",
    "    cnc,\n",
    ")\n",
    "print(\"collected responses\")\n",
    "snippets_tags = pd.read_sql_query(\n",
    "    \"\"\"Select tag_id, snippet_id from snippets_tags where snippet_id in \"\"\"\n",
    "    + snippet_list,\n",
    "    cnc,\n",
    ")\n",
    "tag_list = \"(\" + \",\".join([str(a) for a in snippets_tags[\"tag_id\"].tolist()]) + \")\"\n",
    "tags = pd.read_sql_query(\n",
    "    \"\"\"select id as tag_id, name as tag from tags where id in \"\"\" + tag_list, cnc\n",
    ")\n",
    "\n",
    "snippets_tags = pd.merge(snippets_tags, tags, on=\"tag_id\")\n",
    "tagged_snippets = pd.merge(snippets, snippets_tags, on=\"snippet_id\", how=\"left\")\n",
    "user_list = \"(\" + \",\".join([str(a) for a in assignments[\"user_id\"].tolist()]) + \")\"\n",
    "users = pd.read_sql_query(\n",
    "    \"\"\"select id as user_id, ethnicity, education, household_income, birthday, gender from users where\n",
    "                                 id in \"\"\"\n",
    "    + user_list,\n",
    "    cnc,\n",
    ")\n",
    "user_snippets = pd.merge(tagged_snippets, users, on=\"user_id\", how=\"left\")\n",
    "user_snippets = pd.merge(user_snippets, scout_groups, on=\"assignment_id\", how=\"left\")\n",
    "response_data = pd.merge(responses, questions, on=\"question_id\")\n",
    "response_data = pd.merge(response_data, user_snippets, on=\"snippet_id\", how=\"left\")\n",
    "cnc.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#response_data.to_pickle('mission_'+mission_id+'_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_data['birthday'] = response_data['birthday'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ethnicity_filters:\n",
    "    ethnicities = ethnicity_filters\n",
    "else:\n",
    "    response_data['ethnicity'] = (\n",
    "        response_data['ethnicity'].fillna('missing')\n",
    "    )\n",
    "    ethnicities = response_data['ethnicity'].unique()\n",
    "\n",
    "if education_filters:\n",
    "    educations = education_filters\n",
    "else:\n",
    "    response_data['education'] = (\n",
    "        response_data['education'].fillna('missing')\n",
    "    )\n",
    "    educations = response_data['education'].unique()\n",
    "if tag_filters:\n",
    "    tags = tag_filters\n",
    "else:\n",
    "    response_data['tag'] = (\n",
    "        response_data['tag'].fillna('None')\n",
    "    )\n",
    "    tags = response_data['tag'].unique()\n",
    "if scout_group_filters:\n",
    "    scout_groups = scout_group_filters\n",
    "else:\n",
    "    response_data['scout_group'] = (\n",
    "        response_data['scout_group'].fillna('None')\n",
    "    )\n",
    "    scout_groups = response_data['scout_group'].unique()\n",
    "filtered = response_data[(response_data['ethnicity'].isin(ethnicities)) & \n",
    "                        (response_data['education'].isin(educations)) &\n",
    "                        (response_data['tag'].isin(tags)) &\n",
    "                        (response_data['scout_group'].isin(scout_groups))].copy()\n",
    "filtered_id_list = []\n",
    "for question in question_response_filtering:\n",
    "    part, num = int(question.split('-')[0])-1, int(question.split('-')[1])-1\n",
    "    response = question_response_filtering[question]\n",
    "    ids = filtered [(filtered['part_position'] == part) &\n",
    "                        (filtered['question_position'] == num) &\n",
    "                        (any([response in x for x in filtered['answers']]))][grouping].unique()\n",
    "    filtered_id_list = filtered_id_list + list(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filtered_id_list:\n",
    "    filtered_all = filtered[filtered[\"snippet_id\"].isin(filtered_id_list)].copy()\n",
    "else:\n",
    "    filtered_all = filtered.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(response_data[response_data['part_position'] == 3].groupby('user_id').count()))\n",
    "print(len(filtered[filtered['part_position'] == 3].groupby('user_id').count()))\n",
    "print(len(filtered[filtered['part_position'] == 3].drop_duplicates(['user_id','question_id']).groupby(['user_id']).count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered[filtered['part_position'] == 3].groupby('user_id').first().reset_index().groupby('scout_group').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = MixedFeatureData(\n",
    "    filtered_all,\n",
    "    dependent_variable,\n",
    "    continuous_independent_variables,\n",
    "    binary_independent_variables,\n",
    "    categorical_independent_variables,\n",
    "    positive_outcomes,\n",
    "    negative_outcomes,\n",
    "    demo_independent_variables,\n",
    "    tag_independent_variables,\n",
    "    scout_group_independent_variables,\n",
    "    grouping,\n",
    ")\n",
    "eda = ExploratoryAnalysis(\n",
    "    fd.encoded_features,\n",
    "    fd.independent_variables,\n",
    "    fd.dependent_variable,\n",
    "    fd.question_choices(),\n",
    ")\n",
    "logistic_regression = MixedClassificationModel(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd.raw['scout_group'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(logistic_regression.balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations of Independent Variables\n",
    "### After viewing these you may want to rethink your independent variable choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda.correlation_matrix_plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda.correlation_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_age_today(birthday):\n",
    "    if birthday is not None:\n",
    "        today =  datetime.datetime.today()\n",
    "        #print(today, birthday)\n",
    "        try:\n",
    "            return (today - birthday).days/365.25\n",
    "        except TypeError:\n",
    "            return (today.date() - birthday).days/365.25\n",
    "    return -1    \n",
    "\n",
    "import datetime\n",
    "filtered_all['age'] = filtered_all.apply(lambda row: get_age_today(row['birthday']), axis=1)\n",
    "raw_copy = fd.raw.copy()\n",
    "#raw_copy['birthday'] = raw_copy['birthday'].astype('datetime64[ns]')\n",
    "#raw_copy['age'] = raw_copy.apply(lambda row: get_age_today(row['birthday']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relative Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variances = eda.pca_explained_variances()\n",
    "for i, q_id in enumerate(fd.independent_variables):\n",
    "    print(q_id, round(explained_variances[i],2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Value Decomposition\n",
    "## Data Projected onto a 2D space, and colored by Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda.plot_outcome_clusters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "## Histogram of Predicted Probability of Positive Outcome, colored by Actual Outcome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression.visualize_goodness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression.print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "## Simulated Probability of Positive Outcome controlling for all but one variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for independent_variable in fd.continuous_independent_variables:\n",
    "    if independent_variable not in fd.binary_independent_variables:\n",
    "        logistic_regression.simulate_continuous_outcomes(independent_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for independent_variable in fd.independent_variables:\n",
    "    if independent_variable in fd.binary_independent_variables or\\\n",
    "       independent_variable in fd.dummies:\n",
    "        logistic_regression.simulate_binary_outcomes(independent_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
