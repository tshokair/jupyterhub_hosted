{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO GET STARTED: Enter a mission id below and then select Cell->Run All from the menu above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mission_id = 25614"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib.parse import urlparse\n",
    "from urllib import parse\n",
    "\n",
    "%matplotlib inline\n",
    "FOLLOWER_URL = os.environ['FOLLOWER_URL']\n",
    "                          \n",
    "def make_connection():\n",
    "    url_output = FOLLOWER_URL\n",
    "    url = urlparse(url_output)\n",
    "    conn = psycopg2.connect(\n",
    "        database=url.path[1:],\n",
    "        user=url.username,\n",
    "        password=url.password,\n",
    "        host=url.hostname\n",
    "    )\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(answer, transcription, q_type):\n",
    "    if q_type in ['TextQuestion', 'TitleQuestion']:\n",
    "        return str(answer[0])\n",
    "    else:\n",
    "        if transcription is not None:\n",
    "            return str(transcription)\n",
    "        else:\n",
    "            return \"\"\n",
    "cnc = make_connection()\n",
    "\n",
    "snippets = pd.read_sql_query(\n",
    "    \"\"\"select id as snippet_id from snippets where mission_id = \"\"\"\n",
    "    + str(mission_id),\n",
    "    cnc\n",
    ")\n",
    "snippet_list = (\n",
    "    \"(\" + \",\".join([str(a) for a in snippets[\"snippet_id\"].tolist()]) + \")\"\n",
    ")\n",
    "questions = pd.read_sql_query(\n",
    "    \"\"\"select id as question_id, position + 1 as question_num, type, part_id from questions where mission_id = \"\"\"\n",
    "    + str(mission_id) + \"\"\" and type in ('TitleQuestion','TextQuestion','VideoQuestion')\"\"\"\n",
    "    ,\n",
    "    cnc\n",
    ")\n",
    "question_list = (\n",
    "    \"(\" + \",\".join([str(a) for a in questions[\"question_id\"].tolist()]) + \")\"\n",
    ")\n",
    "\n",
    "part_list = (\n",
    "    \"(\" + \",\".join([str(a) for a in questions[\"part_id\"].tolist()]) + \")\"\n",
    ")\n",
    "\n",
    "parts = pd.read_sql_query(\n",
    "    \"\"\"select id as part_id, position + 1 as part_num from parts\n",
    "    where id in \"\"\"+ part_list,\n",
    "    cnc\n",
    ")\n",
    "questions = pd.merge(questions, parts, on='part_id')\n",
    "responses = pd.read_sql_query(\n",
    "    \"\"\"select id as response_id, question_id, answers from responses where snippet_id in \"\"\"\n",
    "    + snippet_list + \"\"\" and question_id in \"\"\" + question_list,\n",
    "    cnc,\n",
    ")\n",
    "\n",
    "responses = pd.merge(responses, questions, on='question_id')\n",
    "video_response_list = (\n",
    "    \"(\" + \",\".join([\n",
    "        str(a) for a in responses[responses['type'] == 'VideoQuestion']\n",
    "        [\"response_id\"].tolist()]) \n",
    "    + \")\"\n",
    ")  \n",
    "\n",
    "transcripts = pd.read_sql_query(\n",
    "    \"\"\"select transcription, response_id from videos where\n",
    "    response_id in \"\"\"+ video_response_list,\n",
    "    cnc\n",
    ")\n",
    "responses = pd.merge(\n",
    "    responses,\n",
    "    transcripts,\n",
    "    on='response_id',\n",
    "    how ='left'\n",
    ")\n",
    "responses['response'] = responses.apply(\n",
    "    lambda row: get_response(row['answers'],row['transcription'], row['type']),\n",
    "    axis=1\n",
    ")\n",
    "responses['word_count'] = responses.apply(\n",
    "    lambda row: len(row['response'].split()),\n",
    "    axis=1\n",
    ")\n",
    "cnc.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORD COUNT STATS BY QUESTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses.groupby(['part_num','question_num'])['word_count'].agg(['mean','median','std','sum','count']).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WOUNT COUNT STATS BY PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses.groupby(['part_num'])['word_count'].agg(['mean','median','std','sum','count']).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORD COUNT STATS BY QUESTION TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses.groupby(['type'])['word_count'].agg(['mean','median','std','sum','count']).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORD COUNT STATS BY MISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses['word_count'].agg(['mean','median','std','sum','count']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
